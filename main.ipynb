{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"./train.csv\")\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18285, 4)\n",
      "(18285,)\n"
     ]
    }
   ],
   "source": [
    "dataset  = dataset.dropna()\n",
    "# independent features\n",
    "x = dataset.drop('label',axis=1)\n",
    "# dependent features\n",
    "y = dataset[\"label\"]\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\ritik\n",
      "[nltk_data]     pandey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_size = 5000\n",
    "msg = x.copy()\n",
    "msg.reset_index(inplace=True)\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "corpus =[]\n",
    "for i in range(0,len(msg)):\n",
    "    rev = re.sub('[^a-zA-Z]',' ',msg['title'][i])\n",
    "    rev = rev.lower()\n",
    "    rev = rev.split()\n",
    "    rev  = [ps.stem(word) for word in rev if not word in stopwords.words('english')]\n",
    "    rev = ' '.join(rev)\n",
    "    corpus.append(rev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0, 3830, 2353, 3246, 3035, 2012, 4099, 2181,\n",
       "       2242, 2003, 3379])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_len = []\n",
    "for sen in corpus:\n",
    "    sen_len.append(len(sen.split(' ')))\n",
    "max_len = max(sen_len)\n",
    "oneHot = [one_hot(words,voc_size)for words in corpus]\n",
    "embed_doc = pad_sequences(oneHot,padding='pre',maxlen=max_len)\n",
    "embed_doc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 47, 40)            200000    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               56400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 256,501\n",
      "Trainable params: 256,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "embed_features = 40\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size,embed_features,input_length=max_len))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array(embed_doc)\n",
    "y = np.array(y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_te , y_tr, y_te = train_test_split(X,y,test_size=0.33, random_state=42)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "192/192 [==============================] - 6s 25ms/step - loss: 0.4265 - accuracy: 0.7979 - val_loss: 0.3449 - val_accuracy: 0.9065\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.2684 - accuracy: 0.8650 - val_loss: 0.3033 - val_accuracy: 0.9072\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.1544 - accuracy: 0.9406 - val_loss: 0.3211 - val_accuracy: 0.9167\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.1127 - accuracy: 0.9623 - val_loss: 0.4170 - val_accuracy: 0.9173\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.0852 - accuracy: 0.9777 - val_loss: 0.5691 - val_accuracy: 0.9180\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.0640 - accuracy: 0.9864 - val_loss: 0.5641 - val_accuracy: 0.9004\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.0542 - accuracy: 0.9921 - val_loss: 0.7043 - val_accuracy: 0.9072\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 4s 23ms/step - loss: 0.0413 - accuracy: 0.9956 - val_loss: 0.8097 - val_accuracy: 0.9132\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.0355 - accuracy: 0.9973 - val_loss: 0.8625 - val_accuracy: 0.9137\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.0333 - accuracy: 0.9977 - val_loss: 0.8571 - val_accuracy: 0.9090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d75afe6f10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_tr,y_tr, validation_data=(x_te,y_te),epochs=10, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9973c6938f4aad7dcfd49854c1e0cc6453bbf87fb3680ba791d7b26d8dd01db7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
